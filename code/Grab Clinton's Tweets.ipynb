{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Hillary Clinton's Tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only purpose of this notebook is to download the tweets and tweet info into a csv file that can later be handled with Pandas. Not all the columns in the csv file are useful and some will need some careful preprocessing. Below is a description of the fields in the csv file.\n",
    "\n",
    "Column | Description\n",
    "--- | ---\n",
    "id | tweet id\n",
    "source | iPhone or Android (needs preprocessing)\n",
    "text | text of HC's tweets\n",
    "favorite_count | number of favorites the tweet received (set to 0 if retweet and affected by the issue above)\n",
    "retweet_count | number of retweets the tweet received (set to 0 if retweet and affected by the issue above)\n",
    "is_retweet | boolean (affected by the way HC sometimes quotes tweets)\n",
    "original_author | original author of the tweet (biased towards HC because of the issue above)\n",
    "possibly_sensitive | boolean (useless since either no info in the case of Android posts or False for iPhone posts)\n",
    "created_at | day, date, and time when the tweet was posted on HC's page\n",
    "hashtags | hashtags in the tweet\n",
    "user_mentions | Twitter users mentioned in the tweet (only listed if mentioned the typical \"Twitter way\" using @)\n",
    "lang | language (usually english, sometimes undefined)\n",
    "place | place where the tweet was made based on the coordinates\n",
    "place_coord_boundaries | corner coordinates of the bounding box defining the location where the tweet was made "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import tweepy\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import yaml\n",
    "root_dir = \"/Users/gogrean/Documents/kaggle/off_kaggle_ds/elect2016/\"\n",
    "twitter_cred = yaml.load(open(root_dir + 'credentials/twitter.cred'))\n",
    "\n",
    "auth = tweepy.OAuthHandler(twitter_cred['consumer_token'], \n",
    "                           twitter_cred['consumer_secret'])\n",
    "auth.set_access_token(twitter_cred['access_token_key'], \n",
    "                      twitter_cred['access_token_secret'])\n",
    "\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Twitter API limits the user to accessing only the last 3200 tweets. So I'm starting here with the last 3200 tweets that HC posted, and will run the script every few weeks to download new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "page_list=[]\n",
    "for page in tweepy.Cursor(api.user_timeline, screen_name='HillaryClinton', count=200, include_rts=True).pages(17):\n",
    "    page_list.append(page)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If a file with the tweets already exists, only new tweets are added to it. In this case the new tweets will be added at the end of the file, so the tweets will not be in chronological order. Whether a tweet is new or not is decided based on the date and time it was created; if the date and time are already in the file, then the tweet is an old one and it's skipped over."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "root_dir = \"/Users/gogrean/Documents/kaggle/off_kaggle_ds/elect2016/data/\"\n",
    "clintons_tweets_file = \"clintons_tweets.csv\"\n",
    "\n",
    "if os.path.exists(root_dir + clintons_tweets_file):\n",
    "    df = pd.read_csv(root_dir + clintons_tweets_file, header=0)\n",
    "    cols = df.columns.values\n",
    "else:\n",
    "    cols = ['id', 'source', 'text', 'favorite_count', 'retweet_count',  \n",
    "            'is_retweet', 'original_author', 'possibly_sensitive', \n",
    "            'created_at', 'hashtags', 'user_mentions', 'lang', \n",
    "            'place', 'place_coord_boundaries']\n",
    "    df = pd.DataFrame(columns=cols)\n",
    "\n",
    "for page in page_list:\n",
    "    for status in page:\n",
    "        status = status._json\n",
    "        if status['created_at'] in df['created_at'].values:\n",
    "            continue\n",
    "        hashtags = \", \".join([hashtag_item['text'] for hashtag_item in status['entities']['hashtags']])\n",
    "        mentions = \", \".join([mention['screen_name'] for mention in status['entities']['user_mentions']])\n",
    "        try: \n",
    "            status['retweeted_status']\n",
    "        except KeyError:\n",
    "            is_retweet = False\n",
    "        else:\n",
    "            is_retweet = True    \n",
    "\n",
    "        if is_retweet:\n",
    "            n_favorites = 0\n",
    "            n_retweets = 0\n",
    "            original_author = status['retweeted_status']['user']['screen_name']\n",
    "        else:\n",
    "            n_favorites = status['favorite_count']\n",
    "            n_retweets = status['retweet_count']\n",
    "            original_author = status['user']['screen_name']\n",
    "        \n",
    "        try:\n",
    "            location = status['place']['full_name']    \n",
    "        except TypeError:\n",
    "            location = ''\n",
    "        \n",
    "        try:\n",
    "            coordinates = [coord for loc in status['place']['bounding_box']['coordinates'] for coord in loc]\n",
    "        except TypeError:\n",
    "            coordinates = None\n",
    "        \n",
    "        try:\n",
    "            is_sensitive = status['possibly_sensitive']\n",
    "        except KeyError:\n",
    "            is_sensitive = None\n",
    "        \n",
    "        single_tweet_df = pd.DataFrame([[\n",
    "                                        status['id'],\n",
    "                                        status['source'],\n",
    "                                        status['text'],\n",
    "                                        n_favorites,\n",
    "                                        n_retweets,\n",
    "                                        is_retweet, original_author, \n",
    "                                        is_sensitive,\n",
    "                                        status['created_at'],\n",
    "                                        hashtags, mentions, \n",
    "                                        status['lang'],\n",
    "                                        location,\n",
    "                                        coordinates\n",
    "                                        ]], columns=cols)\n",
    "        df = df.append(single_tweet_df, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.to_csv(root_dir + clintons_tweets_file, columns=cols, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
